{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_feature_selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8QMmvX+O/LpoCedoNXngQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaljuvee/datascience/blob/master/notebooks/stats/regression_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NSRSE_SLz9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install sklearn\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEykllYZMT9Y",
        "colab_type": "text"
      },
      "source": [
        "**Background**\n",
        "\n",
        "The simplest case of feature selection is the case where there are numerical input variables and a numerical target for regression predictive modeling, and this can often be done with correlation.\n",
        "\n",
        "\n",
        "**Overview**\n",
        "\n",
        "Using [scikit-learn](https://scikit-learn.org/) libarary we demonstrate:\n",
        "\n",
        "* **Correlation and mutual statistics** - evaluate the importance of numerical input data using the correlation \n",
        "and mutual information statistics.\n",
        "* **Numerical feature selection** - perform feature selection for numerical input data when fitting and evaluating a regression model.\n",
        "* **Tuning with grid search** -  tune the number of features selected in a modeling pipeline using a grid search\n",
        "\n",
        "**Steps**\n",
        "\n",
        "1. Generate Regression Dataset\n",
        "2. Numerical Feature Selection\n",
        "  1. Correlation Feature Selection\n",
        "  2. Mutual Information Feature Selection\n",
        "3. Modeling With Selected Features\n",
        "  1. Model Built Using All Features\n",
        "  2. Model Built Using Correlation Features\n",
        "  3. Model Built Using Mutual Information Features\n",
        "4. Tune the Number of Selected Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o24pYMjPlQZ",
        "colab_type": "text"
      },
      "source": [
        "**1. Generate Regression Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8kJcGsONjCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "# generate regression dataset with 1,000 samples, each with 100 input features where 10 are informative and the remaining 90 are redundant.\n",
        "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQP_4-QHPBBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a43953b4-95f0-441c-c389-ff860e3bf522"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split into train and test sets with 67 percent of the data for training and 33 percent for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# summarize\n",
        "print('Train', X_train.shape, y_train.shape)\n",
        "print('Test', X_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (670, 100) (670,)\n",
            "Test (330, 100) (330,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ZMox5kPslv",
        "colab_type": "text"
      },
      "source": [
        "**2. Numerical Feature Selection**\n",
        "\n",
        "**2.1 Numerical Feature Selection - Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF8J5F8iPqtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d63e2a20-d93c-4da0-c075-7301c0df9a95"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# wrap feature selection logic in a function\n",
        "def select_features_corr(X_train, y_train, X_test):\n",
        "\t# configure to select all features\n",
        "\tfs = SelectKBest(score_func=f_regression, k='all')\n",
        "\t# learn relationship from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\t# transform train input data\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\t# transform test input data\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "# feature selection using correlation, by default\n",
        "X_train_fs, X_test_fs, fs = select_features_corr(X_train, y_train, X_test)\n",
        "\n",
        "# what are scores for the features (ranging from less than 1 to 101)\n",
        "def show_scores():\n",
        "  for i in range(len(fs.scores_)):\n",
        "\t  print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "  # plot the scores\n",
        "  pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "  pyplot.show()\n",
        "\n",
        "show_scores()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 0: 0.009419\n",
            "Feature 1: 1.018881\n",
            "Feature 2: 1.205187\n",
            "Feature 3: 0.000138\n",
            "Feature 4: 0.167511\n",
            "Feature 5: 5.985083\n",
            "Feature 6: 0.062405\n",
            "Feature 7: 1.455257\n",
            "Feature 8: 0.420384\n",
            "Feature 9: 101.392225\n",
            "Feature 10: 0.387091\n",
            "Feature 11: 1.581124\n",
            "Feature 12: 3.014463\n",
            "Feature 13: 0.232705\n",
            "Feature 14: 0.076281\n",
            "Feature 15: 4.299652\n",
            "Feature 16: 1.497530\n",
            "Feature 17: 0.261242\n",
            "Feature 18: 5.960005\n",
            "Feature 19: 0.523219\n",
            "Feature 20: 0.003365\n",
            "Feature 21: 0.024178\n",
            "Feature 22: 0.220958\n",
            "Feature 23: 0.576770\n",
            "Feature 24: 0.627198\n",
            "Feature 25: 0.350687\n",
            "Feature 26: 0.281877\n",
            "Feature 27: 0.584210\n",
            "Feature 28: 52.196337\n",
            "Feature 29: 0.046855\n",
            "Feature 30: 0.147323\n",
            "Feature 31: 0.368485\n",
            "Feature 32: 0.077631\n",
            "Feature 33: 0.698140\n",
            "Feature 34: 45.744046\n",
            "Feature 35: 2.047376\n",
            "Feature 36: 0.786270\n",
            "Feature 37: 0.996190\n",
            "Feature 38: 2.733533\n",
            "Feature 39: 63.957656\n",
            "Feature 40: 231.885540\n",
            "Feature 41: 1.372448\n",
            "Feature 42: 0.581860\n",
            "Feature 43: 1.072930\n",
            "Feature 44: 1.066976\n",
            "Feature 45: 0.344656\n",
            "Feature 46: 13.951551\n",
            "Feature 47: 3.575080\n",
            "Feature 48: 0.007299\n",
            "Feature 49: 0.004651\n",
            "Feature 50: 1.094585\n",
            "Feature 51: 0.241065\n",
            "Feature 52: 0.355137\n",
            "Feature 53: 0.020294\n",
            "Feature 54: 0.154567\n",
            "Feature 55: 2.592512\n",
            "Feature 56: 0.300175\n",
            "Feature 57: 0.357798\n",
            "Feature 58: 3.060090\n",
            "Feature 59: 0.890357\n",
            "Feature 60: 122.132164\n",
            "Feature 61: 2.029982\n",
            "Feature 62: 0.091551\n",
            "Feature 63: 1.081123\n",
            "Feature 64: 0.056041\n",
            "Feature 65: 2.930717\n",
            "Feature 66: 0.054886\n",
            "Feature 67: 1.332787\n",
            "Feature 68: 0.145579\n",
            "Feature 69: 0.986331\n",
            "Feature 70: 0.092661\n",
            "Feature 71: 0.083219\n",
            "Feature 72: 0.198847\n",
            "Feature 73: 2.065792\n",
            "Feature 74: 0.236594\n",
            "Feature 75: 0.512608\n",
            "Feature 76: 1.095650\n",
            "Feature 77: 0.015359\n",
            "Feature 78: 2.193730\n",
            "Feature 79: 1.574530\n",
            "Feature 80: 5.360863\n",
            "Feature 81: 0.041874\n",
            "Feature 82: 5.717705\n",
            "Feature 83: 0.436560\n",
            "Feature 84: 5.594438\n",
            "Feature 85: 0.000065\n",
            "Feature 86: 0.026748\n",
            "Feature 87: 0.408422\n",
            "Feature 88: 2.092557\n",
            "Feature 89: 9.568498\n",
            "Feature 90: 0.642445\n",
            "Feature 91: 0.065794\n",
            "Feature 92: 198.705931\n",
            "Feature 93: 0.073807\n",
            "Feature 94: 1.048605\n",
            "Feature 95: 0.004106\n",
            "Feature 96: 0.042110\n",
            "Feature 97: 0.034228\n",
            "Feature 98: 0.792433\n",
            "Feature 99: 0.015365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIFZIOrKSXeB",
        "colab_type": "text"
      },
      "source": [
        "The bar chart above clearly shows 8 to 10 features are a lot more important than the other features. We could set k=10 When configuring the SelectKBest to select these top features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-PooHLLS0Og",
        "colab_type": "text"
      },
      "source": [
        "**2.2 Numerical Feature Selection - Mutual Information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvJQQ7uQTMI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d383b305-82c3-48c8-c256-78eac68edb7a"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "# configure to select all features\n",
        "# feature selection\n",
        "def select_features_mutualinfo(X_train, y_train, X_test):\n",
        "\t# configure to select all features\n",
        "\tfs = SelectKBest(score_func=mutual_info_regression, k='all')\n",
        "\t# learn relationship from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\t# transform train input data\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\t# transform test input data\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "# feature selection using correlation\n",
        "X_train_fs, X_test_fs, fs = select_features_mutualinfo(X_train, y_train, X_test)\n",
        "\n",
        "show_scores()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 0: 0.045484\n",
            "Feature 1: 0.000000\n",
            "Feature 2: 0.000000\n",
            "Feature 3: 0.000000\n",
            "Feature 4: 0.024816\n",
            "Feature 5: 0.000000\n",
            "Feature 6: 0.022659\n",
            "Feature 7: 0.000000\n",
            "Feature 8: 0.000000\n",
            "Feature 9: 0.074320\n",
            "Feature 10: 0.000000\n",
            "Feature 11: 0.000000\n",
            "Feature 12: 0.000000\n",
            "Feature 13: 0.000000\n",
            "Feature 14: 0.020390\n",
            "Feature 15: 0.004307\n",
            "Feature 16: 0.000000\n",
            "Feature 17: 0.000000\n",
            "Feature 18: 0.016566\n",
            "Feature 19: 0.003688\n",
            "Feature 20: 0.007579\n",
            "Feature 21: 0.018640\n",
            "Feature 22: 0.025206\n",
            "Feature 23: 0.017967\n",
            "Feature 24: 0.069173\n",
            "Feature 25: 0.000000\n",
            "Feature 26: 0.022232\n",
            "Feature 27: 0.000000\n",
            "Feature 28: 0.007849\n",
            "Feature 29: 0.012849\n",
            "Feature 30: 0.017402\n",
            "Feature 31: 0.008083\n",
            "Feature 32: 0.047321\n",
            "Feature 33: 0.002829\n",
            "Feature 34: 0.028968\n",
            "Feature 35: 0.000000\n",
            "Feature 36: 0.071652\n",
            "Feature 37: 0.027969\n",
            "Feature 38: 0.000000\n",
            "Feature 39: 0.064796\n",
            "Feature 40: 0.137695\n",
            "Feature 41: 0.008732\n",
            "Feature 42: 0.003983\n",
            "Feature 43: 0.000000\n",
            "Feature 44: 0.009387\n",
            "Feature 45: 0.000000\n",
            "Feature 46: 0.038385\n",
            "Feature 47: 0.000000\n",
            "Feature 48: 0.000000\n",
            "Feature 49: 0.000000\n",
            "Feature 50: 0.000000\n",
            "Feature 51: 0.000000\n",
            "Feature 52: 0.000000\n",
            "Feature 53: 0.008130\n",
            "Feature 54: 0.041779\n",
            "Feature 55: 0.000000\n",
            "Feature 56: 0.000000\n",
            "Feature 57: 0.000000\n",
            "Feature 58: 0.031228\n",
            "Feature 59: 0.002689\n",
            "Feature 60: 0.146192\n",
            "Feature 61: 0.000000\n",
            "Feature 62: 0.000000\n",
            "Feature 63: 0.000000\n",
            "Feature 64: 0.018194\n",
            "Feature 65: 0.021368\n",
            "Feature 66: 0.046071\n",
            "Feature 67: 0.034707\n",
            "Feature 68: 0.033530\n",
            "Feature 69: 0.002262\n",
            "Feature 70: 0.018332\n",
            "Feature 71: 0.000000\n",
            "Feature 72: 0.000000\n",
            "Feature 73: 0.074876\n",
            "Feature 74: 0.000000\n",
            "Feature 75: 0.004429\n",
            "Feature 76: 0.002617\n",
            "Feature 77: 0.031354\n",
            "Feature 78: 0.000000\n",
            "Feature 79: 0.000000\n",
            "Feature 80: 0.000000\n",
            "Feature 81: 0.033931\n",
            "Feature 82: 0.010400\n",
            "Feature 83: 0.019373\n",
            "Feature 84: 0.000000\n",
            "Feature 85: 0.033191\n",
            "Feature 86: 0.000000\n",
            "Feature 87: 0.028745\n",
            "Feature 88: 0.000000\n",
            "Feature 89: 0.000000\n",
            "Feature 90: 0.000000\n",
            "Feature 91: 0.017698\n",
            "Feature 92: 0.129797\n",
            "Feature 93: 0.000000\n",
            "Feature 94: 0.002171\n",
            "Feature 95: 0.029995\n",
            "Feature 96: 0.000000\n",
            "Feature 97: 0.014428\n",
            "Feature 98: 0.000000\n",
            "Feature 99: 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNjVDqn8h47S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLCeqErFmdFg",
        "colab_type": "text"
      },
      "source": [
        "**3. Modeling with Features**\n",
        "\n",
        "**3.1 Using All Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igYnmN7smlKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc87a56d-3d0a-4dba-c87e-1111633b6c57"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLKJbPkQqTX8",
        "colab_type": "text"
      },
      "source": [
        "**3.2. Model with Correlation Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkMeSd4m3K1",
        "colab_type": "text"
      },
      "source": [
        "Objective - use a subset or combination of features that achieves MAE < 0.086"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDoU-_-GnAXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "639bfc39-1d59-409f-ee9d-b09bbcff8b05"
      },
      "source": [
        "\n",
        "# feature selection\n",
        "def select_features_10_corr(X_train, y_train, X_test):\n",
        "\t# configure to select a subset of features\n",
        "\tfs = SelectKBest(score_func=f_regression, k=10)\n",
        "\t# learn relationship from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\t# transform train input data\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\t# transform test input data\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "# feature selection by correlation\n",
        "X_train_fs, X_test_fs, fs = select_features_10_corr(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 2.740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwq32CAKoLZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "321edc61-7b62-4cf7-9fc1-e9dfe591445d"
      },
      "source": [
        "# feature selection\n",
        "def select_features_88_corr(X_train, y_train, X_test):\n",
        "\t# configure to select a subset of features\n",
        "\tfs = SelectKBest(score_func=f_regression, k=88)\n",
        "\t# learn relationship from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\t# transform train input data\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\t# transform test input data\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "  # feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features_88_corr(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWaHs-Q7pkgt",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion** - running the example reports the performance of the model on 88 of the 100 input features selected using the **correlation statistic** reduces MAE to 0.085"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwxq6r5pqeF9",
        "colab_type": "text"
      },
      "source": [
        "**3.3 Model with Mutual Information Features Subset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F18GjwdxpoId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84b07bde-9fd1-4861-cfcb-03882e7721e7"
      },
      "source": [
        "# feature selection\n",
        "def select_features_88_mutualinfo(X_train, y_train, X_test):\n",
        "\t# configure to select a subset of features\n",
        "\tfs = SelectKBest(score_func=mutual_info_regression, k=88)\n",
        "\t# learn relationship from training data\n",
        "\tfs.fit(X_train, y_train)\n",
        "\t# transform train input data\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\t# transform test input data\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features_88_mutualinfo(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6oMs68IqB3P",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion** - running the example reports the performance of the model on 88 of the 100 input features selected using the **mutuual information statistic** reduces MAE to 0.085"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_6x4AA0q9-W",
        "colab_type": "text"
      },
      "source": [
        "**4. Tune the Number of Selected Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRp14IlqJ_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "e798d200-fee3-4d42-c411-d6c475cc9822"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "num_features = [i for i in range(X.shape[1]-19, X.shape[1]+1)]\n",
        "# enumerate each number of features\n",
        "results = list()\n",
        "for k in num_features:\n",
        "\t# create pipeline\n",
        "\tmodel = LinearRegression()\n",
        "\tfs = SelectKBest(score_func=mutual_info_regression, k=k)\n",
        "\tpipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
        "\t# evaluate the model\n",
        "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "\tresults.append(scores)\n",
        "\t# summarize the results\n",
        "\tprint('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-26872aa3b9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# summarize the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOz1u_Vhsw9n",
        "colab_type": "text"
      },
      "source": [
        "**Resources**\n",
        "\n",
        "* [Rergression Features Selection](https://machinelearningmastery.com/feature-selection-for-regression-data/) by Jason Brownlee"
      ]
    }
  ]
}